# -*- coding: utf-8 -*-
"""ê¸´ê¸‰ë„íŒë³„_í›ˆë ¨ìš©_MTL_ì „ì²˜ë¦¬.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19vZ8cUREOpNvoCK_GnGDUbpgB9H0NvZQ

# ğŸ“¦ ê¸´ê¸‰ë„íŒë³„ â€” í›ˆë ¨ìš© **MTL ì „ì²˜ë¦¬** (Colab)
**ëª©í‘œ:** í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ **ê¸´ê¸‰ë„(urgency)**ì™€ **ê°ì •(sentiment)**ì„ **ë™ì‹œì— í•™ìŠµ**í•  ìˆ˜ ìˆë„ë¡ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.

## ì…ë ¥
- `Processed_Data/calls_df_preprocessed.feather`
- `Processed_Data/utts_df_preprocessed.feather`  *(ì´ì „ EDA ë…¸íŠ¸ë¶ì—ì„œ ìƒì„±ë¨)*

## ì¶œë ¥
- `MTL_ready/` í´ë” ì•„ë˜ì— **CSV + Parquet** ë™ì‹œ ì €ì¥
  - `X_train / X_test` (ì…ë ¥ íŠ¹ì§•: `full_text`, `turn_count`, `initial_response_ms`)
  - `y_train_urgency / y_test_urgency` (í•˜=0, ì¤‘=1, ìƒ=2)
  - `y_train_sentiment / y_test_sentiment` (ê¸°íƒ€ë¶€ì •=0, ë‹¹í™©/ë‚œì²˜=1, ë¶ˆì•ˆ/ê±±ì •=2, ì¤‘ë¦½=3)

## ì›ì¹™
- **íƒ€ê¹ƒ ëˆ„ì„¤ ë°©ì§€:** ê°ì •ì€ ì˜ˆì¸¡ ëŒ€ìƒì´ë¯€ë¡œ ì…ë ¥ í”¼ì²˜ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
- **ê·¸ë£¹ ëˆ„ìˆ˜ ìµœì†Œí™”:** ë™ì¼ `recordId`ëŠ” ê°™ì€ ë¶„í• ì— ë“¤ì–´ê°€ë„ë¡ ì¸ë±ìŠ¤ ë³´ê´€
- **ì¬í˜„ì„±:** CSVë§Œìœ¼ë¡œë„ í•™ìŠµ ê°€ëŠ¥, Parquetì€ ê³ ì†/ì•ˆì •/ì¬í˜„ ìš©ë„ë¡œ ì¶”ê°€ ì €ì¥
"""

# â¬‡ï¸ 1) Google Drive ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# ğŸ“ 2) ê²½ë¡œ ì„¤ì •
import os
PROCESSED_DIR = "/content/drive/MyDrive/project1/Processed_Data"
OUT_DIR = os.path.join(PROCESSED_DIR, "MTL_ready")
os.makedirs(OUT_DIR, exist_ok=True)
print("INPUT :", PROCESSED_DIR)
print("OUTPUT:", OUT_DIR)

# ğŸ“¥ 3) Feather ë¡œë“œ
import pandas as pd

calls_fp = os.path.join(PROCESSED_DIR, "calls_df_preprocessed.feather")
utts_fp  = os.path.join(PROCESSED_DIR, "utts_df_preprocessed.feather")

calls_df = pd.read_feather(calls_fp)
utts_df  = pd.read_feather(utts_fp)

print(f"âœ… ë¡œë“œ ì™„ë£Œ â€” calls_df: {calls_df.shape}, utts_df: {utts_df.shape}")
display(calls_df.head(2))
display(utts_df.head(2))

# ğŸ§© 4) í†µí™” ì „ì²´ í…ìŠ¤íŠ¸ ë³‘í•©(full_text)
full_texts = (
    utts_df
      .sort_values(["recordId","startAt"])
      .groupby("recordId")["text"]
      .apply(lambda s: " ".join(map(str, s.dropna())))
      .reset_index()
      .rename(columns={"text":"full_text"})
)

# ê¸°ë³¸ í”¼ì²˜ + íƒ€ê¹ƒ í›„ë³´ë§Œ ì¶”ì¶œ
feature_cols = ["recordId", "turn_count", "initial_response_ms", "urgencyLevel", "sentiment"]
base = calls_df[feature_cols].copy()

df = (base.astype({"recordId": str})
          .merge(full_texts.astype({"recordId": str}), on="recordId", how="inner"))
print("âœ… í…ìŠ¤íŠ¸ ë³‘í•©:", df.shape)
display(df.head(3))

# ğŸ§¼ 5) ê²°ì¸¡/íƒ€ì… í´ë¦°ì—… + íƒ€ê¹ƒ ì¸ì½”ë”©
import numpy as np

# ê¸°ë³¸ ê²°ì¸¡ ì²˜ë¦¬
df["turn_count"] = df["turn_count"].fillna(df["turn_count"].median())
med_resp = df["initial_response_ms"].median()
df["initial_response_ms"] = df["initial_response_ms"].fillna(med_resp)

# íƒ€ê¹ƒ ì¸ì½”ë”©
urgency_map = {"í•˜":0, "ì¤‘":1, "ìƒ":2}
sentiment_map = {"ê¸°íƒ€ë¶€ì •":0, "ë‹¹í™©/ë‚œì²˜":1, "ë¶ˆì•ˆ/ê±±ì •":2, "ì¤‘ë¦½":3}

df["y_urgency"]   = df["urgencyLevel"].map(urgency_map)
df["y_sentiment"] = df["sentiment"].map(sentiment_map)

# ë¼ë²¨ ê²°ì¸¡ ì œê±°
df = df.dropna(subset=["y_urgency", "y_sentiment"]).copy()
df["y_urgency"]   = df["y_urgency"].astype("int64")
df["y_sentiment"] = df["y_sentiment"].astype("int64")

# ğŸ”’ ì…ë ¥ Xì—ì„œ íƒ€ê¹ƒ ê´€ë ¨ ì»¬ëŸ¼ ì œê±° (ëˆ„ì„¤ ë°©ì§€)
X = df[["turn_count", "initial_response_ms", "full_text"]].copy()
y_u = df["y_urgency"].copy()
y_s = df["y_sentiment"].copy()

print("âœ… í”¼ì²˜/íƒ€ê¹ƒ í™•ì •")
print("X columns:", list(X.columns))
print("y_urgency classes:", sorted(y_u.unique()))
print("y_sentiment classes:", sorted(y_s.unique()))

# ğŸ”€ 6) Train/Test ë¶„í•  (ë‘ íƒ€ê¹ƒ ì¡°í•©ìœ¼ë¡œ stratify)
from sklearn.model_selection import train_test_split

combo = df["y_urgency"].astype(str) + "_" + df["y_sentiment"].astype(str)

X_train, X_test, y_train_u, y_test_u, y_train_s, y_test_s = train_test_split(
    X, y_u, y_s,
    test_size=0.2,
    random_state=42,
    stratify=combo
)

# (ì„ íƒ) recordId ì¸ë±ìŠ¤ ë³´ê´€ â€” ë™ì¼ í†µí™” ëˆ„ìˆ˜ ì ê²€ìš©
idx_train = X_train.index.to_series().map(df["recordId"])
idx_test  = X_test.index.to_series().map(df["recordId"])

print("âœ… ë¶„í•  ì™„ë£Œ")
print("Train:", X_train.shape, "| Test:", X_test.shape)
print("Train recordId ìƒ˜í”Œ:", idx_train.head().tolist())

# ğŸ’¾ 7) ì €ì¥ (CSV + Parquet)
os.makedirs(OUT_DIR, exist_ok=True)

# CSV
X_train.to_csv(os.path.join(OUT_DIR, "X_train.csv"), index=False)
X_test.to_csv(os.path.join(OUT_DIR, "X_test.csv"), index=False)
y_train_u.to_csv(os.path.join(OUT_DIR, "y_train_urgency.csv"), index=False)
y_test_u.to_csv(os.path.join(OUT_DIR, "y_test_urgency.csv"), index=False)
y_train_s.to_csv(os.path.join(OUT_DIR, "y_train_sentiment.csv"), index=False)
y_test_s.to_csv(os.path.join(OUT_DIR, "y_test_sentiment.csv"), index=False)

# Parquet
X_train.to_parquet(os.path.join(OUT_DIR, "X_train.parquet"), index=False)
X_test.to_parquet(os.path.join(OUT_DIR, "X_test.parquet"), index=False)
y_train_u.to_frame("y_urgency").to_parquet(os.path.join(OUT_DIR, "y_train_urgency.parquet"), index=False)
y_test_u.to_frame("y_urgency").to_parquet(os.path.join(OUT_DIR, "y_test_urgency.parquet"), index=False)
y_train_s.to_frame("y_sentiment").to_parquet(os.path.join(OUT_DIR, "y_train_sentiment.parquet"), index=False)
y_test_s.to_frame("y_sentiment").to_parquet(os.path.join(OUT_DIR, "y_test_sentiment.parquet"), index=False)

print("âœ… ì €ì¥ ì™„ë£Œ â†’", OUT_DIR)
print("ğŸ“„ íŒŒì¼ ëª©ë¡:")
for f in sorted(os.listdir(OUT_DIR)):
    if f.endswith((".csv",".parquet")):
        print(" -", f)

# ğŸ” 8) ê°„ë‹¨ ë¬´ê²°ì„± ì ê²€
import numpy as np

def class_dist(y, name):
    vc = y.value_counts(normalize=True).sort_index()
    print(f"{name} class dist:", {int(k): round(float(v), 3) for k, v in vc.items()})

class_dist(y_train_u, "y_train_urgency")
class_dist(y_test_u,  "y_test_urgency")
class_dist(y_train_s, "y_train_sentiment")
class_dist(y_test_s,  "y_test_sentiment")

assert set(y_train_u.unique()).issubset({0,1,2})
assert set(y_test_u.unique()).issubset({0,1,2})
assert set(y_train_s.unique()).issubset({0,1,2,3})
assert set(y_test_s.unique()).issubset({0,1,2,3})

print("âœ… ë¬´ê²°ì„± OK")