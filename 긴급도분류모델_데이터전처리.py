# -*- coding: utf-8 -*-
"""
ê¸´ê¸‰ë„ë¶„ë¥˜ëª¨ë¸_ë°ì´í„°ì „ì²˜ë¦¬
- WAV íŒŒì¼ ë° JSON ë¼ë²¨ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ DataFrame ìƒì„±
- Wav2Vec2 pretrained ëª¨ë¸ë¡œ ìŒì„± êµ¬ê°„ ì„ë² ë”© ì¶”ì¶œ
- ê²°ê³¼ ì €ì¥
"""

import os
import glob
import re
import json
import zipfile
from concurrent.futures import ThreadPoolExecutor

import pandas as pd
import numpy as np
import librosa
import torch
from tqdm import tqdm
from transformers import Wav2Vec2Processor, Wav2Vec2Model

# =========================================================
# 0ï¸âƒ£ Google Drive Mount (Colab í™˜ê²½ì—ì„œë§Œ í•„ìš”)
# =========================================================
from google.colab import drive
drive.mount('/content/drive')

# =========================================================
# 1ï¸âƒ£ ZIP íŒŒì¼ ì••ì¶• í•´ì œ
# =========================================================
def unzip_file(zip_path, extract_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {extract_dir}")

# WAV íŒŒì¼
wav_zip = "/content/drive/MyDrive/urgency_data/Validation/1.á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_á„€á…ªá†¼á„Œá…®_á„€á…®á„€á…³á†¸.zip"
wav_extract_dir = "/content/audio_dataset/Validation/Wave"
unzip_file(wav_zip, wav_extract_dir)

# JSON ë¼ë²¨ íŒŒì¼
label_zip = "/content/drive/MyDrive/urgency_data/Validation/2.á„…á…¡á„‡á…¦á†¯á„…á…µá†¼á„ƒá…¦á„‹á…µá„á…¥/VL_á„€á…ªá†¼á„Œá…®_á„€á…®á„€á…³á†¸.zip"
label_extract_dir = "/content/audio_dataset/Validation/Label"
unzip_file(label_zip, label_extract_dir)

# =========================================================
# 2ï¸âƒ£ WAV íŒŒì¼ ìŠ¤ìº” ë° ID â†’ ê²½ë¡œ ë§¤í•‘
# =========================================================
def build_wav_map(base_path):
    all_wav_files = glob.glob(os.path.join(base_path, "**/*.wav"), recursive=True)
    print(f"ğŸ” íƒìƒ‰ëœ WAV íŒŒì¼ ìˆ˜: {len(all_wav_files)}")

    wav_map = {}
    for wav in all_wav_files:
        basename = os.path.basename(wav)
        name = os.path.splitext(basename)[0]

        match = re.match(r"^([A-Za-z0-9]+)_[0-9]{8}", name)
        file_id = match.group(1) if match else name.split("_")[0]
        wav_map[str(file_id)] = wav

    print(f"âœ… ì¶”ì¶œëœ wav ID ê°œìˆ˜: {len(wav_map)}")
    return wav_map

wav_map = build_wav_map(wav_extract_dir)

# =========================================================
# 3ï¸âƒ£ JSON íŒŒì¼ ì½ê³  DataFrame ìƒì„±
# =========================================================
def build_dataframe(json_dir, wav_map):
    json_files = glob.glob(os.path.join(json_dir, '**/*.json'), recursive=True)
    all_rows = []

    for file in tqdm(json_files, desc="Reading JSON"):
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        json_id = str(data.get('_id'))
        wav_path = wav_map.get(json_id, None)

        common_labels = {
            '_id': json_id,
            'sentiment': data.get('sentiment'),
            'urgencyLevel': data.get('urgencyLevel'),
            'disasterLarge': data.get('disasterLarge'),
            'disasterMedium': data.get('disasterMedium'),
            'triage': data.get('triage'),
            'gender': data.get('gender'),
            'mediaType': data.get('mediaType'),
            'address': data.get('address'),
            'symptom': ','.join(data.get('symptom', [])),
            'wav_file_path': wav_path
        }

        for u in data['utterances']:
            all_rows.append({
                **common_labels,
                'utterance_id': u['id'],
                'startAt': u['startAt'],
                'endAt': u['endAt'],
                'text': u['text'],
                'speaker': u['speaker']
            })

    df = pd.DataFrame(all_rows)
    df = df[df["wav_file_path"].notna()]
    df = df[df["wav_file_path"].apply(os.path.exists)]
    print(f"âœ… ìœ íš¨í•œ wav íŒŒì¼ ìˆ˜: {len(df)}")
    return df

df_u = build_dataframe(label_extract_dir, wav_map)

# =========================================================
# 4ï¸âƒ£ Wav2Vec2 ëª¨ë¸ ë¡œë“œ
# =========================================================
MODEL_NAME = "kresnik/wav2vec2-large-xlsr-korean"
device = "cuda" if torch.cuda.is_available() else "cpu"

processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)
model = Wav2Vec2Model.from_pretrained(MODEL_NAME).to(device)
model.eval()
target_sr = 16000

# =========================================================
# 5ï¸âƒ£ ì˜¤ë””ì˜¤ êµ¬ê°„ë³„ ë¡œë”© í•¨ìˆ˜
# =========================================================
def load_waveform_segment(wav_path, start_ms, end_ms, sr=target_sr, min_sec=0.5):
    waveform, _ = librosa.load(wav_path, sr=sr, mono=True)
    start_sample = int(start_ms / 1000 * sr)
    end_sample = int(end_ms / 1000 * sr)
    segment = waveform[start_sample:end_sample]
    return segment if len(segment) >= int(min_sec * sr) else None

# =========================================================
# 6ï¸âƒ£ Streaming ë°©ì‹ ì„ë² ë”© ì¶”ì¶œ
# =========================================================
def extract_embeddings(df, batch_size=32, num_workers=8):
    embeddings = []

    with torch.no_grad():
        for i in tqdm(range(0, len(df), batch_size), desc="Extracting"):
            batch_rows = df.iloc[i:i+batch_size]

            # CPU ë³‘ë ¬ë¡œ waveform ë¡œë“œ
            with ThreadPoolExecutor(max_workers=num_workers) as executor:
                waveforms = list(executor.map(
                    lambda r: load_waveform_segment(r.wav_file_path, r.startAt, r.endAt),
                    batch_rows.itertuples(index=False)
                ))

            valid = [(wf, idx) for idx, wf in enumerate(waveforms) if wf is not None]
            if not valid:
                embeddings.extend([None]*len(batch_rows))
                continue

            batch_embeddings = [None]*len(batch_rows)
            for wf, idx in valid:
                input_values = processor(wf, sampling_rate=target_sr, return_tensors="pt").input_values.to(device)
                outputs = model(input_values)
                hidden_states = outputs.last_hidden_state.squeeze(0).cpu().numpy()
                batch_embeddings[idx] = np.mean(hidden_states, axis=0)

            embeddings.extend(batch_embeddings)
    return embeddings

embeddings = extract_embeddings(df_u)
df_u["wav2vec2_embedding"] = embeddings
df_u = df_u[df_u["wav2vec2_embedding"].notna()].reset_index(drop=True)

# =========================================================
# 7ï¸âƒ£ ê²°ê³¼ ì €ì¥
# =========================================================
np.save(
    "/content/drive/MyDrive/train_embedding_split_utter/valid_wav2vec2_embeddings_split.npy",
    np.stack(df_u["wav2vec2_embedding"].to_numpy())
)
df_u.to_csv(
    "/content/drive/MyDrive/train_embedding_split_utter/valid_ê´‘ì£¼_êµ¬ê¸‰_split.csv",
    index=False
)

print("âœ… Streaming ë°©ì‹ Embedding ì¶”ì¶œ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ")
